\chapter{INTRODUÇÃO} \label{cha:introducao}

O uso, armazenamento e controle de dados é um tema muito discutido na área de computação desde seus primórdios até os dias de hoje. Dessa forma, muitos métodos, algoritmos e termos surgiram ao longo do tempo com o objetivo de gerenciar de forma eficiente esses dados. O surgimento de tais ferramentas computacionais e métodos de armazenamento é de grande importância para a evolução da área.

Atualmente, os métodos mais comuns são bancos de dados relacionais e \textit{\gls{datawarehouse}s} usando computação em nuvem \cite{PastAndFutureTrendsData19}. Além disso, pesquisas nos campos de mineração de dados e aprendizagem de máquina cresceram bastante recentemente, de modo a prover técnicas que permitissem analisar dados complexos e variados entre si \cite{ProgrammingBigData22}. Um grande desafio é o fato de algoritmos sequenciais não serem otimizados o suficiente para lidar com dados em grande quantidade. Assim, computadores de alta performance, com múltiplos \textit{\gls{cores}}, sistemas na nuvem e algoritmos paralelos e distribuídos são usados para lidar com esses empecilhos de \textit{Big Data} \cite{ProgrammingBigData22}.

\textit{Big Data} refere-se a grandes conglomerados de dados complexos sobre os quais não é possível aplicar ferramentas tradicionais de processamento, armazenamento ou análise \cite{OptmizationSoftwareHadoop18}. Estima-se que, em 2025, os dados atuais criados, capturados ou replicados atinjam 175 Zettabytes, ou seja 175.000.000.000 Gigabytes \cite{DigitalizationWorld18}.

A fim de lidar com essa enorme quantidade de dados, foi desenvolvido pelo Google o \textit{MapReduce}, um modelo de programação com uma implementação associada criado para processar e gerar grandes conglomerados de dados. Esse modelo é inspirado nos conceitos de mapear e reduzir, ou seja, aplicar uma operação que conecta cada item da base de dados a um determinado par de chaves e valores, e então executar uma operação de reduzir, que une os valores que compartilham chaves \cite{MapReduce08}. Com essas operações é possível paralelizar dados em grandes quantidades e fazer uso de mecanismos de reutilização para facilitar a busca e a manipulação desses mesmos dados.

Um dos \textit{\gls{framework}s} mais populares que utiliza o \textit{MapReduce} é o \textit{Hadoop}, desenvolvido pela Apache em 2006 e capaz de armazenar e processar de Gigabytes a Petabytes de dados eficientemente, optando por usar múltiplos computadores (\textit{clusters}) em paralelo \cite{HadoopBook15}.

O \textit{Hadoop MapReduce} é um \textit{\gls{framework}} extremamente personalizável e adaptável. Dessa forma, frequentemente utiliza-se o processo de \textit{\gls{tuning}}, que consiste em modificar os mais de 190 parâmetros desse \textit{\gls{framework}} de modo a maximizar a eficiência de um \textit{cluster Hadoop}. Esses parâmetros podem ser alterados em diversas combinações e podem ter efeitos tanto no \textit{cluster} quantos nas tarefas (\textit{jobs}) do processo.

O trabalho tem como objetivo avaliar o comportamento do \textit{Hadoop MapReduce} antes e depois do \textit{\gls{tuning}} de alguns parâmetros de configuração, observando através de métricas de \textit{\gls{benchmark}} se houve melhora na performance, considerando medidas como tempo e uso de memória.

Para atingir o objetivo estabelecido, foram feitos estudos teóricos dos parâmetros através da literatura apresentada principalmente por \textcite{HadoopBook15} e \textcite{ProHadoop09} - que apresentam em detalhe as ferramentas usadas no desenvolvimento do trabalho - e estudos práticos através de testes com as ferramentas em execução. O propósito dos testes executados é melhorar o desempenho do \textit{Hadoop MapReduce} e os experimentos realizados mostram o quão poderoso é o processo de \textit{\gls{tuning}}, visto que foi obtida uma melhora de desempenho de mais de cinquenta por cento (50\%) do tempo de execução das funções \textit{Map} e \textit{Reduce}.

O trabalho está organizado da seguinte forma: o \autoref{cha:refteorico} apresenta os fundamentos teóricos e as ferramentas que serão utilizadas nos experimentos e referenciadas durante o desenvolvimento do texto; o \autoref{cha:otimizacaomapreduce} apresenta em detalhes os parâmetros do \textit{Hadoop MapReduce} e as ferramentas de \textit{\gls{benchmark}} utilizadas para obtenção das métricas. O \autoref{cha:experimentos} expõe o ambiente no qual os experimentos serão executados e os resultados obtidos através dos ajustes dos parâmetros de configuração da ferramenta. Finalmente, no \autoref{cha:conclusao} é feita a conclusão do trabalho.