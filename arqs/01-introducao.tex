\chapter{INTRODUÇÃO} \label{cha:introducao}

\section{CONTEXTO} \label{sec:contexto}

O uso, armazenamento e controle de dados é um tema muito discutido na área de computação desde seus primórdios até os dias de hoje. Dessa forma, muitos métodos e algoritmos e termos surgiram ao longo do tempo com o objetivo de gerenciar de forma eficiente esses dados. O surgimento de tais ferramentas computacionais e métodos de armazenamento é de grande importância para a evolução da área.

Atualmente, os métodos mais comuns são bancos de dados relacionais e \textit{\gls{datawarehouse}s} usando computação em nuvem \cite{PastAndFutureTrendsData19}. Além disso, pesquisas nos campos de mineração de dados e aprendizagem de máquina cresceram bastante recentemente, de modo a prover técnicas que permitissem analisar dados complexos e variados entre si \cite{ProgrammingBigData22}. Um grande desafio é o fato de algoritmos sequenciais não serem otimizados o suficiente para lidar com dados em grande quantidade. Assim, computadores de alta performance, com múltiplos \textit{cores}, sistemas na nuvem e algoritmos paralelos e distribuídos são usados para lidar com esses empecilhos de \textit{Big Data} \cite{ProgrammingBigData22}.

\textit{Big Data} refere-se a grandes conglomerados de dados complexos sobre os quais não é possível aplicar ferramentas tradicionais de processamento, armazenamento ou análise \cite{OptmizationSoftwareHadoop18}. Estima-se que em 2025 os dados atuais criados, capturados ou replicados atinjam 175 Zettabytes, ou seja 175.000.000.000 Gigabytes \cite{DigitalizationWorld18}.

A fim de lidar com essa enorme quantidade de dados, foi desenvolvido pelo Google o \textit{MapReduce}, um modelo de programação com uma implementação associada feito para processar e gerar grandes conglomerados de dados. Esse modelo é inspirado nos conceitos de mapear e reduzir, ou seja, aplicar uma operação que conecta cada item da base de dados a um determinado par de chaves e valores, e então aplicar uma operação de reduzir, que une os valores que compartilham chaves \cite{MapReduce08}. Com essas operações é possível paralelizar dados em grandes quantidades e utilizar mecanismos de reutilização para facilitar a busca e a manipulação destes.

Um dos \textit{\gls{framework}s} mais populares que utiliza o \textit{MapReduce} é o \textit{Hadoop}, desenvolvido pela Apache em 2006 e capaz de armazenar e processar de Gigabytes a Petabytes de dados eficientemente, optando por usar múltiplos computadores (\textit{clusters}) em paralelo \cite{HadoopBook15}.

\section{OBJETIVO} \label{sec:objetivo}

O \textit{Hadoop MapReduce} é um \textit{\gls{framework}} extremamente personalizável e adaptável. Dessa forma, frequentemente utiliza-se o processo de \textit{tuning}, que consiste em modificar os mais de 190 parâmetros desse \textit{\gls{framework}} de modo a maximizar a eficiência de um \textit{cluster Hadoop}. Esses parâmetros podem ser alterados em diversas combinações e podem ter efeitos tanto no \textit{cluster} quantos nas tarefas (\textit{jobs}) do processo.

Esse trabalho tem como objetivo avaliar o comportamento do \textit{Hadoop MapReduce} antes e depois do \textit{tuning} de alguns parâmetros de configuração, observando através de métricas de \textit{benchmark} se houve melhora na performance, considerando medidas como tempo e uso de memória.

\section{ESTRUTURA DO TRABALHO} \label{sec:estrtura}

[TODO: ESTRUTURA DO TRABALHO]