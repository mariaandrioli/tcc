\chapter{REFERENCIAL TEÓRICO} \label{cha:refteorico}

Este capítulo tem como objetivo apresentar detalhadamente os conceitos técnicos que serão utilizados ao longo do trabalho. A \autoref{sec:clusters} introduz o conceito de \textit{clusters}. A \autoref{sec:mapreduce} apresenta o \textit{MapReduce}, o modelo de manipulação de dados feito pelo Google e a \autoref{sec:hadoop} trata do \textit{Hadoop}, o \textit{\gls{framework}} desenvolvido pela Apache. Por fim, a \autoref{sec:virtualizacao} explica virtualização, contêiners e a ferramenta Docker.

\section{CLUSTERS} \label{sec:clusters}

Um \textit{cluster} é um conjunto de computadores que trabalham juntos paralelamente em uma determinada aplicação. Cada computador desse conjunto é usualmente chamado de nodo. Além disso, existem diversas categorias de \textit{clusters}, dependendo do problema que eles buscam computar \cite{GoldmanApache12}.

Algumas aplicações comuns de \textit{clusters} são modelagem de clima, simulação de acidentes automotivos, mineração de dados e aplicações da área de astrofísica. Além disso, é comumente visto em aplicações comerciais como bancos e serviços de email \cite{ClusterGridCloudComparison11}.

Uma das maiores vantagens desse tipo de instalação é a tolerância de falhas, pois os sistemas conseguem continuar suas tarefas caso um nodo pare de funcionar. Além disso, é altamente escalável com a adição de novos nodos, não precisa de manutenção frequente e tem um gerenciamento centralizado. Por fim, uma das suas maiores possíveis vantagens é o balanceamento de carga, que busca atingir o equilíbrio entre as tarefas de cada nodo de modo a otimizar os recursos \cite{ClusterGridCloudComparison11}.

\section{MAPREDUCE} \label{sec:mapreduce}

\textit{MapReduce} é um modelo de programação associado a uma implementação que tem como objetivo processar, manipular e gerar grandes \textit{datasets} de modo eficiente, escalável e com aplicações no mundo real. As computações acontecem de acordo com funções de mapeamento e redução e o sistema do \textit{MapReduce} paraleliza essas computações entre grandes \textit{clusters}, lidando com possíveis falhas, escalonamentos e uso eficiente de rede e discos \cite{MapReduce08}.

As operações de mapeamento e redução são baseadas em conceitos presentes em linguagens funcionais e fazem com que seja possível fazer diversas reutilizações, assim lidando com tolerância de falhas \cite{MapReduce08}.

\subsection{Modelo de programação}\label{ssec:mapreducemodelo}

A computação recebe um conjunto de pares (CHAVE, VALOR) e produz um conjunto de pares de (CHAVE, VALOR). O usuário cria as funções \textit{Map} e \textit{Reduce} de acordo com seu uso. \textit{Map} recebe um único par (CHAVE, VALOR) e produz um conjunto intermediário de pares. Em seguida, a biblioteca \textit{MapReduce} agrupa os valores com a mesma chave, os quais servirão de entrada para a função \textit{Reduce}. Nesse momento a função \textit{Reduce} unifica os valores com a mesma chave de modo a criar um conjunto menor, sendo possível dessa forma lidar com listas muito grandes para a memória disponível \cite{MapReduce08}. 

Entre o momento que são executadas as funções \textit{Map} e \textit{Reduce}, existe a fase \textit{Shuffle}, que é criada automaticamente em tempo de execução e executa operações de ordenação (\textit{sort}) e junção (\textit{merge}) \cite{ProHadoop09}. Para \textcite{HadoopBook15}, a operação \textit{Shuffle} é um dos fatores mais influentes no bom desempenho de aplicações \textit{MapReduce}, uma vez que operações de ordenação e junções podem prejudicar ou melhorar muito um algoritmo conforme sua implementação.

Como exemplo, considere-se o problema de contar quantas vezes determinada palavra aparece em um documento. Nesse problema, as funções \textit{Map} e \textit{Reduce} seriam similares aos seguintes pseudocódigos \cite{MapReduce08}:

\begin{lstlisting}[caption={Exemplo de função Map em pseudocódigo adaptado de \cite{MapReduce08}}, label=code:codigo1]
map(String chave, String valor):
// chave: nome do documento
// valor: conteudo do documento

  para cada palavra W em valor:
    criaIntermediario(W, 1);
\end{lstlisting}

% \newpage
\begin{lstlisting}[caption={Exemplo de função Reduce em pseudocódigo adaptado de \cite{MapReduce08}}, label=code:codigo2]
reduce(String chave, Iterador valores):
// chave: uma palavra
// valores: lista de contagens

  int resultado = 0;
  para cada V em valores:
    resultado = resultado + 1;
  cria(resultado);
\end{lstlisting}

\newpage
A função \textit{Map} gera um objeto intermediário de cada palavra associada a uma lista do seu número de ocorrências no texto e a função \textit{Reduce} soma os valores até que essas ocorrências por palavras sejam totalizadas. Além disso, o usuário cria um configuração de \textit{MapReduce} com os parâmetros de entrada e saída e eventuais parâmetros de \textit{tuning}.

Para exemplificar ainda mais, considere um arquivo de texto com três linhas nas quais estão as seguintes frases, respectivamente, uma em cada linha: "vamos para casa", "na minha casa", "para na casa". Nesse exemplo, a função \textit{Map} é chamada três vezes, uma para cada linha, gerando os pares (CHAVE, VALOR) intermediários, um para cada palavra encontrada no texto, como é mostrado na \autoref{fig:fig1}. Para cada palavra distinta ("vamos", "para", "casa", "na", "minha"), é executada a função \textit{Reduce}, que soma quantas vezes cada uma dessas palavras apareceu no texto e gera um arquivo de saída.

\figura{Execução Genérica do MapReduce}{1.00}{fig/fig1.png}{A autora (2022)}{fig1}{}{}

\subsection{Execução do MapReduce}\label{ssec:execucaomapreduce}

O \textit{MapReduce} funciona usando uma estrutura Cliente/Servidor sobre um \textit{cluster} que, segundo \textcite{MapReduce08}, consiste em primeiramente particionar os dados de entrada em blocos de tamanho já definidos e depois distribuir cópias do programa MapReduce entre cada um desses blocos. Existe uma cópia Master, que é responsável por repartir as tarefas (\textit{tasks}), enquanto as demais cópias - denominadas Workers - recebem da Master as tarefas junto com os arquivos de entrada. Ao finalizar a execução de uma tarefa do tipo \textit{Map}, a cópia Worker responsável repassa a Master os arquivos de saída e esta repassa à um Worker esse arquivo com a tarefa de \textit{Reduce}. Por fim, esse worker executa a redução, lendo os pares intermediários que passaram pela fase \textit{Shuffle} e agrupando as instâncias de mesma chave. Quando todas as tarefas \textit{Map} e \textit{Reduce} forem executadas, o programa é finalizado.

Na \autoref{fig:fig1} foi possível ver como o \textit{MapReduce} funcionaria em pequena escala. Uma das maiores vantagens do \textit{MapReduce} é, no entanto, sua escalabilidade, visto que ele permite uma execução distribuída entre uma grande quantidade de nodos. A \autoref{fig:fig2}  representa uma execução genérica do \textit{MapReduce}, descrita no parágrafo acima.

\figura{Exemplo de execução do MapReduce}{.900}{fig/fig2.png}{Adaptado de \cite{MapReduce08}}{fig2}{}{}

\section{HADOOP} \label{sec:hadoop}

\textit{Hadoop} é um \textit{\gls{framework}} desenvolvido na linguagem Java pela Apache Software Foundation com os seguintes princípios arquiteturais, segundo \textcite{ImprovingNavarro18}:
\begin{itemize}
  \item A possibilidade de escalar o sistema ao adicionar nodos no \textit{cluster}.
  \item Possibilidade de funcionar bem em \textit{hardware} que não necessite ser caro e de luxo.
  \item Tolerância a falhas, com implementações que as identificam e permitem que o sistema funcione independente delas acontecerem.
  \item Fornecimento de serviços para que o usuário foque no problema que deseja resolver.
\end{itemize}

Esse \textit{\gls{framework}} disponibiliza ferramentas para que o usuário possa escrever as funções necessárias em diversas linguagens de programação, conforme a necessidade do programador. O \textit{\gls{framework}} funciona na mesma estrutura de Cliente/Servidor apresentada anteriormente, utilizada pelo \textit{MapReduce}. Além disso, oferece ao programador um sistema paralelo e distribuído (\textit{Hadoop HDFS}), com os recursos ocultos ao usuário, mas capaz de lidar com a comunicação entre as máquinas e quaisquer falhas que possam vir a ocorrer e o escalonamento das tarefas.

Além do \textit{Hadoop Map Reduce} e do \textit{Hadoop HDFS}, existem outros subprojetos do Hadoop que compôem sua estrutura principal: o \textit{Hadoop Common}, que fornece ferramentas comuns aos outros subprojetos  o \textit{Hadoop YARN}, um \textit{\gls{framework}} para escalonamento de tarefas e gerenciamento de recursos em \textit{clusters}.

\subsection{Hadoop Common}\label{ssec:hadoopcommon}

Esse subprojeto contém os utilitários e bibliotecas comuns aos outros subprojetos. Por exemplo, funções de manipulação de arquivos, funções auxiliares de serialização de dados, etc \cite{GoldmanApache12}.

\subsection{Hadoop HDFS}\label{ssec:hadoophdfs}

Segundo \textcite{HDFSDesign20} o \textit{Hadoop HDFS} é um sistema de arquivos distribuídos criado para funcionar em \textit{hardware} facilmente obtido e relativamento barato. Suas características principais são a alta capacidade de lidar com falhas e a possibilidade de ser usado com aplicações que possuem grande quantidades de dados como entrada.

Uma instância HDFS é composta de centenas ou milhares de máquinas, cada uma responsável por armazenar uma parte dos dados do sistema. Dessa forma, a rápida detecção e recuperação de falhas é essencial para sua estrutura. Seu \textit{design} foi pensado em aplicações de processamento de dados em blocos e o tamanho de seus arquivos pode variar entre Giga e Terabytes. Além disso, é adaptado para funcionar em diferentes plataformas e prover interfaces que possibilitam mover a aplicação para perto dos dados, permitindo que qualquer operação computacional aplicada seja muito mais eficiente \cite{HDFSDesign20}.

O \textit{Hadoop HDFS} também possui uma estrutura Cliente/Servidor, em que o \textit{Namenode} - responsável por gerenciar o sistema e regular o acessos aos arquivos - é o nodo Master e os \textit{Datanodes} - responsáveis por gerenciar o armazenamento dos nodos aos quais eles estão conectados - são os nodos Worker. O sistema é implementado usando uma estrutura comum de diretórios na qual é possível criar, mover, renomear e remover arquivos, mas ainda não implementa funções como quota de usuários, permissões de acesso ou \textit{links} simbólicos \cite{HDFSDesign20}.

Uma das características essenciais desse sistema é sua capacidade de lidar com grandes quantidades de dados. Segundo \textcite{HDFSDesign20}, isso é feito através do armazenamento dos arquivos como uma sequência de blocos, cujo tamanho e fator de replicação são configuráveis pelo usuário, mas possuem um valor padrão de 64MB. Periodicamente, o \textit{Namenode} recebe dos \textit{Datanodes} um sinal indicando se o funcionamento está correto. O posicionamento e a quantidade de réplicas de um bloco é crítica na análise da boa performance do HDFS, e é um dos fatores que o diferencia de outros sistemas de arquivos distribuídos. Quando executada de forma otimizada, pode aumentar confiabilidade, disponibilidade e uso de redes do sistema.


\subsection{Hadoop MapReduce} \label{ssec:hadoopmapreduce}

O \textit{Hadoop MapReduce} é um \textit{\gls{framework}} que implementa o modelo de programação \textit{MapReduce} para facilitar a criação de aplicações que são capazes de processar grandes quantidades de dados em paralelo em \textit{clusters} de uma forma confiável e com tolerância a falhas. 

Esse \textit{\gls{framework}} é constituído de um \textit{Job} responsável por dividir os arquivos de entrada em blocos independentes que serão processados pelas tarefas (\textit{tasks}) \textit{Map}, ordenados na fase \textit{Shuffle} e inseridos nas tarefas \textit{Reduce} de forma paralela. Os arquivos de entrada e saída são armazenados no sistema de arquivos e o sistema é responsável pelo escalonamento, agendamento e reexecução de tarefas que tenham falhado \cite{HadoopMapReduce22}.

A estrutura Cliente/Servidor tem como nodo Master o \textit{JobTracker} e como nodos Worker os \textit{TaskTrackers}. Como apresentado anteriormente, o nodo Master designa as tarefas e os nodos Worker as executam. A aplicação do programador fornece o local dos arquivos de entrada e saída, a implementação das funções de \textit{Map} e \textit{Reduce} e outros parâmetros de configuração do \textit{Job}. Então, o cliente \textit{Hadoop} envia o \textit{Job} e o arquivo de configuração para o \textit{JobTracker} que distribui as tarefas e controla o funcionamento desse \textit{Job}.

\subsection{Hadoop YARN} \label{ssec:hadoopyarn}

O \textit{Hadoop YARN} é um subprojeto que tem como objetivo dividir as funcionalidades de gerenciamento de recursos de escalonamento de tarefas em módulos diferentes, tendo então um gerenciador global de recursos e um gerenciador local por aplicação \cite{GoldmanApache12}. 

O gerenciador global trabalha em conjunto com um gerenciador de nodos responsável pelos contêiners e pelo monitoramento de uso de recursos, como CPU, memória, uso de disco e uso de redes, assim como o repasse dessas informações para o gerenciador global \cite{HadoopYarn22}.

O YARN foi adicionado ao \textit{Hadoop} versão 2.0 permitindo a separação das camadas de gerenciamento de recursos que possam ser alocados pela aplicação. Com essa camada independente, ilustrada na \autoref{fig:fig3}, as aplicações \textit{MapReduce} podem ser utilizadas em conjunto com aplicações não \textit{MapReduce}. Além disso, esse formato de implementação possibilita economizar custos com o melhor aproveitamento dos nodos \cite{KobylinskaMartins14}. 

\figura{Nova arquitetura do Hadoop 2.0}{.700}{fig/fig3.png}{\cite{KobylinskaMartins14}}{fig3}{}{}

\newpage
\section{VIRTUALIZAÇÃO} \label{sec:virtualizacao}

Virtualização é o processo de criar um ambiente ou uma versão virtual de algum componente computacional, tal como \textit{hardwares}, dispositivos de armazenamento e recursos de rede. A virtualização permite que haja economia nos custos de \textit{hardware}, melhoria na recuperação em caso de falhas e redução da necessidade de espaço físico para \textit{datacenters} \cite{PortnoyVirtualization12}. 

Uma das técnicas da virtualização é a utilização de contêiners. Contêiners, uma virtualização a nível de sistema, permitem que existam múltiplos espaços do usuário por cima de um determinada kernel de sistema. 

\figura{Arquitetura Docker}{0.850}{fig/fig4.png}{\cite{DockerDocs22}}{fig4}{}{}
\newpage
Docker é uma ferramenta que tem como objetivo automatizar a implantação de aplicações em contêiners, cuja estrutura geral está ilustrada na \autoref{fig:fig4}. Essa ferramenta empilha uma implantação de uma aplicação em cima de um ambiente de execução em um contêiner, ou seja, simula um ambiente virtual de modo que o programador possa trabalhar com sua aplicação em produção de forma extremamente configurável para as suas necessidades. Para isso, o Docker utiliza um recurso de imagem, que se refere aos arquivos de sistemas que determinada aplicação necessita para ser executada. Então, esses arquivos são empilhados entre si e servem como uma receita para construção de um ou de múltiplos contêiners \cite{DockerBook14}.

