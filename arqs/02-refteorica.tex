\chapter{REFERENCIAL TEÓRICO} \label{cha:refteorico}

Esse capítulo tem como objetivo apresentar detalhadamente os conceitos técnicos que serão utilizados ao longo do trabalho. A \autoref{sec:clusters} introduz o conceito de \textit{clusters}. A \autoref{sec:mapreduce} apresenta o \textit{MapReduce}, o modelo de manipulação de dados feito pelo Google e a \autoref{sec:hadoop} trata do \textit{Hadoop}, o \textit{framework} desenvolvido pela Apache. Por fim, a \autoref{sec:docker} explica virtualização, contêiners e a ferramenta Docker.

\section{CLUSTERS} \label{sec:clusters}

Um \textit{cluster} é um conjunto de computadores que trabalham juntos paralelamente em uma determinada aplicação. Cada computador desse conjunto é usualmente chamado de nodo. Além disso, existem diversas categorias de clusters dependendo do problema que eles buscam computar \cite{GoldmanApache12}.

Algumas aplicações comuns de \textit{clusters} são modelagem de clima, simulação de acidentes automotivos, mineração de dados e aplicações da área de astrofísica. Além disso, é comumente visto em aplicações comerciais como bancos e serviços de email \cite{ClusterGridCloudComparison11}.

Uma das maiores vantagens desse tipo de instalação é a tolerância de falhas, pois os sistemas conseguem continuar suas tarefas caso um nodo pare de funcionar. Além disso, é altamente escalável com a adição de novos nodos, não precisa de manutenção frequente e tem um gerenciamento centralizado. Por fim, uma das suas maiores possíveis vantagens é o balanceamento de carga, que busca atingir o equilíbrio entre as tarefas de cada nodo de modo a otimizar os recursos \cite{ClusterGridCloudComparison11}.

\section{MAPREDUCE} \label{sec:mapreduce}

\textit{MapReduce} é um modelo de programação associado a uma implementação que tem como objetivo processar, manipular e gerar grandes \textit{datasets} de modo eficiente, escalável e com aplicações no mundo real. As computações acontecem de acordo com funções de mapeamento e redução e o sistema do \textit{MapReduce} paraleliza essa computações entre grandes \textit{clusters}, lidando com possíveis falhas, escalonamentos e uso eficiente de rede e discos \cite{MapReduce08}.

As operações de mapeamento e redução são baseadas em conceitos presentes em linguagens funcionais e fazem com que seja possível fazer diversas reutilizações, assim lidando com tolerância de falhas \cite{MapReduce08}.

\subsection{Modelo de programação}\label{ssec:mapreducemodelo}

A computação recebe um conjunto de pares (VALOR, CHAVE) e produz um conjunto de pares de (VALOR, CHAVE). O usuário cria as funções \textit{Map} e \textit{Reduce} de acordo com seu caso de uso. \textit{Map} recebe um único par (VALOR, CHAVE) e produz um conjunto intermediário de pares. Em seguida, a biblioteca \textit{MapReduce} agrupa os valores com a mesma chave e esses valores servirão de entrada para a função \textit{Reduce}. A função \textit{Reduce} então junta os valores com a mesma chave de modo a criar um conjunto menor, sendo possível dessa forma lidar com listas muito grandes para a memória disponível \cite{MapReduce08}. 

Entre o momento que são executadas as funções \textit{Map} e \textit{Reduce}, existe a fase \textit{Shuffle}, que é criada automaticamente em tempo de execução e executa operações de ordenação (\textit{sort}) e junção (\textit{merge}) \cite{ProHadoop09}. Para \textcite{HadoopBook15}, a operação \textit{Shuffle} é um dos fatores mais influentes no bom desempenho de aplicações \textit{MapReduce}, já que operações de ordenação e junções podem prejudicar ou melhorar muito um algoritmo conforme sua implementação.

Como exemplo, considerando o problem de contar quantas vezes determinada palavra aparece em um documento. Nesse problema, as funções \textit{Map} e \textit{Reduce} seriam similares aos seguintes pseudocódigos \cite{MapReduce08}:

\begin{lstlisting}[caption={Exemplo de função Map em pseudocódigo adaptado de \cite{MapReduce08}}, label=code:codigo1]
map(String chave, String valor):
// chave: nome do documento
// valor: conteudo do documento

  para cada palavra W em valor:
    criaIntermediario(W, 1);
\end{lstlisting}

% \newpage
\begin{lstlisting}[caption={Exemplo de função Reduce em pseudocódigo adaptado de \cite{MapReduce08}}, label=code:codigo2]
reduce(String chave, Iterador valores):
// chave: uma palavra
// valores: lista de contagens

  int resultado = 0;
  para cada V em valores:
    resultado = resultado + 1;
  cria(resultado);
\end{lstlisting}

\newpage
A função \textit{Map} gera um objeto intermediário de cada palavra associada a uma lista do seu número de occorrências no texto e a função \textit{Reduce} soma os valores até ter o total de ocorrências por palavra. Além disso, o usuário cria um configuração de \textit{MapReduce} com os parâmetros de entrada e saída e eventuais parâmetros de \textit{tuning}.

Para exemplificar ainda mais, considere um arquivo de texto com três linhas nas quais estão as seguintes frases, respectivamente, uma em cada linha: "vamos para casa", "na minha casa", "para na casa". Nesse exemplo, a função \textit{Map} é chamada três vezes, uma para cada linha, gerando os pares (CHAVE, VALOR) intermediários, um para cada palavra encontrada no texto, como é exemplificado na \autoref{fig:fig1}. Para cada palavra distinta ("vamos", "para", "casa", "na", "minha"), é executada a função \textit{Reduce}, que soma quantas vezes cada uma dessas palavras apareceu no texto e gera um arquivo de saída.

\figura{Execução Genérica do MapReduce}{1.00}{fig/fig1.png}{A autora (2022)}{fig1}{}{}

\subsection{Execução do MapReduce}\label{ssec:execucaomapreduce}

O \textit{MapReduce} funciona usando uma estrutura Cliente/Servidor sobre um \textit{cluster} que, segundo \textcite{MapReduce08} consiste em primeiramente particionar os dados de entrada em bloco de tamanho já definidos e distribuir cópias do programa MapReduce entre cada um desses blocos. Existe uma cópia Master, que é responsável por distribuir as tarefas (\textit{tasks}), enquanto as demais cópias - denominadas Workers - recebem da Master as tarefas junto com os arquivos de entrada. Ao finalizar a execução de uma tarefa do tipo \textit{Map}, a cópia Worker responsável repassa à Master os arquivos de saída e esta repassa à um Worker esse arquivo com a tarefa de \textit{Reduce}. Por fim, esse worker executa a redução, lendo os pares intermediários que passaram pela fase \textit{Shuffle} e agrupando as instâncias de mesma chave. Quando todas as tarefas \textit{Map} e \textit{Reduce} forem executadas, o programa é finalizado.

Na \autoref{fig:fig1} foi possível ver como o \textit{MapReduce} funcionaria em pequena escala. Uma das maiores vantagens do \textit{MapReduce} é, no entanto, sua escalabilidade, visto que ele permite uma execução distribuída entre uma grande quantidade de nodos. A \autoref{fig:fig2}  representa uma execução genérica do \textit{MapReduce}, descrita no parágrafo acima.

\figura{Exemplo de execução do MapReduce}{.900}{fig/fig2.png}{Adaptado de \cite{MapReduce08}}{fig2}{}{}

\section{HADOOP} \label{sec:hadoop}

\textit{Hadoop} é um \textit{framework} desenvolvido na linguagem Java pela Apache Software Foundation com os seguintes princípios arquiteturais, segundo \textcite{ImprovingNavarro18}:
\begin{itemize}
  \item A possibilidade de escalar o sistema ao adicionar nodos no \textit{cluster}.
  \item Possibilidade de funcionar bem em \textit{hardware} que não necessite ser caro e de luxo.
  \item Tolerância a falhas, com implementações que identificam estas e permitem que o sistema funcione independente delas acontecerem.
  \item Fornecimento de serviços para que o usuário foque no problema que deseja resolver.
\end{itemize}

Esse \textit{framework} disponibiliza ferramentas para que o usuário possa escrever as funções necessárias em diversas linguagens de programação, conforme a necessidade do programador. O \textit{framework} funciona na mesma estrutura de Cliente/Servidor apresentada anteriormente, utilizada pelo \textit{MapReduce}. Além disso, oferece ao programador um sistema paralelo e distribuído (\textit{Hadoop HDFS}), com os recursos ocultos ao usuário, mas capaz de lidar com a comunicação entre as máquinas, quaisquer falhas que possam vir a ocorrer e o escalonamento das tarefas.

Além do \textit{Hadoop Map Reduce} e do \textit{Hadoop HDFS}, existem outros subprojetos do Hadoop que compôe sua estrutura principal: o \textit{Hadoop Common}, que fornece ferramentas comuns aos outros subprojetos e \textit{Hadoop YARN}, um \textit{framework} para escalonamento de tarefas e gerenciamento de recursos em \textit{clusters}.

\subsection{Hadoop Common}\label{ssec:hadoopcommon}

Esse subprojeto contém os utilitários e bibliotecas comuns aos outros subprojetos. Por exemplo, funções de manipulação de arquivos, funções auxiliares de serialização de dados, etc \cite{GoldmanApache12}.

\subsection{Hadoop HDFS}\label{ssec:hadoophdfs}

Segundo \textcite{HDFSDesign20} o \textit{Hadoop HDFS} é um sistema de arquivos distribuídos feito para funcionar em \textit{hardware} facilmente obtido e relativamento barato. Suas características principais são a alta capacidade de lidar com falhas e a possibilidade de ser usado com aplicações que tem grande quantidades de dados como entrada.

Uma instância HDFS é composta de centenas ou milhares de máquinas, cada um responsável por armazenar uma parte dos dados do sistema. Dessa forma, a rápida detecção e recuperação de falhas é essencial para sua estrutura. Seu \textit{design} foi pensado em aplicações de processamento de dados em blocos e o tamanho de seus arquivos pode variar entre giga e terabytes. Além disso, é adaptado para funcionar em diferentes plataformas e prover interfaces que possibilitam mover a aplicação para perto dos dados, permitindo com que qualquer operação computacional aplicada seja muito mais eficiente \cite{HDFSDesign20}.

O \textit{Hadoop HDFS} também possui uma estrutura Cliente/Servidor, em que o \textit{Namenode} - responsável por gerenciar o sistema e regular o acessos aos arquivos - é o nodo Master e os \textit{Datanodes} - gerenciam o armazenamento dos nodos aos quais eles estão conectados - são os nodos Worker. O sistema é implementado usando uma estrutura comum de diretórios na qual é possível criar, mover, renomear e remover arquivos e diretórios, mas ainda não implementa funções como quota de usuários, permissões de acesso ou links simbólicos \cite{HDFSDesign20}.

Uma das características essenciais desse sistema é sua capacidade de lidar com grandes quantidades de dados. Segundo \textcite{HDFSDesign20}, isso é feito através do armazenamento dos arquivos como uma sequência de blocos, cujo tamanho e fator de replicação são configuráveis pelo usuário, mas possuem um valor padrão de 64MB. Periodicamente, o \textit{Namenode} recebe dos \textit{Datanodes} um sinal indicando se o funcionamento está correto. O posicionamento e quantidade de réplicas de um bloco é crítica na análise da boa performance do HDFS, e é um dos fatores que o diferencia de outros sistemas de arquivos distribuídos. Quando executada de forma otimizada, pode aumentar confiabilidade, disponibilidade e uso de redes do sistema.


\subsection{Hadoop MapReduce} \label{ssec:hadoopmapreduce}

O \textit{Hadoop MapReduce} é um \textit{framework} que implementa o modelo de programação \textit{MapReduce} para facilitar a criação de aplicações que são capazes de processar grandes quantidades de dados em paralelo em \textit{clusters} de uma forma confiável e com tolerância a falhas. 

Esse \textit{framework} é constituído de um \textit{Job} responsável por dividir os arquivos de entrada em blocos independentes que serão processados pelas tarefas (\textit{tasks}) \textit{Map}, ordenados na fase \textit{Shuffle} e inseridos nas tarefas \textit{Reduce} de forma paralela. Os arquivos de entrada e saída são armazenados no sistema de arquivos e o sistema é responsável pelo escalonamento, agendamento e reexecução de tarefas que tenham falhado \cite{HadoopMapReduce22}.

A estrutura Cliente/Servidor tem como nodo Master o \textit{JobTracker} e como nodos Worker os \textit{TaskTrackers}. Como apresentado anteriormente, o nodo Master designa as tarefas e os nodos Worker as executam. A aplicação do programador fornece o local dos arquivos de entrada e saída, a implementação das funções de \textit{Map} e \textit{Reduce} e outros parâmetros de configuração do \textit{Job}. Então, o cliente \textit{Hadoop} envia o \textit{Job} e o arquivo de configuração para o \textit{JobTracker} que distribui as tarefas e controla o funcionamento desse \textit{Job}.

\subsection{Hadoop YARN} \label{ssec:hadoopyarn}

O \textit{Hadoop YARN} é um subprojeto que tem como objetivo dividir as funcionalidade de gerenciamento de recursos de escalonamento de tarefas em módulos diferentes, tendo então um gerenciador global de recursos de um gerenciado local por aplicação \cite{GoldmanApache12}. 

O gerenciador global trabalha em conjunto com um gerenciador de nodos responsável pelos contêiners e pelo monitoramento de uso de recursos, como CPU, memória, uso de disco e uso de redes, assim como o repasse dessas informações para o gerenciador global \cite{HadoopYarn22}.

O YARN foi adicionado ao \textit{Hadoop} versão 2.0 permitindo a separação das camadas de gerenciamento de recursos que possam ser alocados pela aplicação. Com essa camada independente, como é visto na \autoref{fig:fig3} é possível que aplicações \textit{MapReduce} possam ser utilizadas em conjunto com aplicações não \textit{MapReduce}. Além disso, esse formato de implementação possibilita economizar custos com o melhor aproveitamento dos nodos \cite{KobylinskaMartins14}. 

\figura{Nova arquitetura do Hadoop 2.0}{.700}{fig/fig3.png}{\cite{KobylinskaMartins14}}{fig3}{}{}

\newpage
\section{DOCKER} \label{sec:docker}

Virtualização é o processo de criar um ambiente ou uma versão virtual de algum componente computacional, tal como \textit{hardwares}, dispositivos de armazenamento e recursos de rede. A virtualização permite que haja economia nos custos de \textit{hardware}, melhoria na recuperação em caso de falhas e redução da necessidade de espaço físico para \textit{datacenters} \cite{PortnoyVirtualization12}. 

Uma das técnicas da virtualização é a utilização de contêiners. Contêiners, uma virtualização a nível de sistema, permite que existam múltiplos espaços do usuário por cima de um determinada kernel de sistema. 

Docker é uma ferramenta que tem como objetivo automatizar a implantação de aplicações em contêiners. Essa ferramenta empilha uma implantação de uma aplicação em cima de um ambiente de execução em um contêiner, ou seja, simula um ambiente virtual de modo que o programador possa trabalhar com sua aplicação em produção de forma extremamente configurável para as suas necessidades. Para isso, o Docker utiliza um recurso de imagem, que se refere aos arquivos de sistemas que determinada aplicação necessita para ser executada. Então, esses arquivos são empilhados entre si e servem como uma receita para construção de um ou múltiplos contêiners \cite{DockerBook14}. Na \autoref{fig:fig4} está exemplificado a estrutura geral da arquitetura do Docker.

Nesse trabalho será utilizada a imagem do Hadoop distribuída pela Apache de modo que o framework possa ser devidamente simulado, configurado e testado.

\figura{Arquitetura Docker}{0.850}{fig/fig4.png}{\cite{DockerDocs22}}{fig4}{}{}