\chapter{REFERENCIAL TEÓRICO} \label{cha:refteorico}

Este capítulo tem como objetivo apresentar detalhadamente os conceitos técnicos que serão utilizados ao longo do trabalho. A \autoref{sec:clusters} introduz o conceito de \textit{clusters}. A \autoref{sec:mapreduce} apresenta o \textit{MapReduce}, o modelo de manipulação de dados feito pelo Google e a \autoref{sec:hadoop} trata do \textit{Hadoop}, o \textit{\gls{framework}} desenvolvido pela  Software Foundation. Por fim, a \autoref{sec:virtualizacao} explica virtualização, contêineres e a ferramenta Docker.

\section{CLUSTERS} \label{sec:clusters}

Um \textit{cluster} é um conjunto de computadores que trabalham juntos paralelamente em uma determinada aplicação. Cada computador desse conjunto é usualmente chamado de nodo. Além disso, existem diversas categorias de \textit{clusters}, dependendo do problema que eles buscam computar \cite{GoldmanApache12}.

Algumas aplicações comuns de \textit{clusters} são modelagem de clima, simulação de acidentes automotivos, mineração de dados e aplicações na área de astrofísica. Além disso, é comumente visto em aplicações que necessitam de computações complexas \cite{Nwobodo2015}.

Uma das maiores vantagens desse tipo de instalação é a tolerância de falhas, porque os sistemas conseguem continuar suas tarefas caso um nodo pare de funcionar. Além disso, é altamente escalável com a adição de novos nodos, não precisa de manutenção frequente, tem um gerenciamento centralizado e possui balanceamento de carga, funcionalidade que busca atingir o equilíbrio entre as tarefas de cada nodo de modo a otimizar os recursos \cite{ClusterGridCloudComparison11}.

\section{MAPREDUCE} \label{sec:mapreduce}

\textit{MapReduce} é um modelo de programação associado a uma implementação que tem como objetivo processar, manipular e gerar grandes \textit{datasets} de modo eficiente, escalável e com aplicações no mundo real. As computações acontecem de acordo com funções de mapeamento e redução e o sistema do \textit{MapReduce} paraleliza essas computações entre grandes \textit{clusters}, lidando com possíveis falhas, escalonamentos e uso eficiente de rede e discos \cite{MapReduce08}.

As operações de mapeamento e redução são baseadas em conceitos presentes em linguagens funcionais e fazem com que seja possível fazer diversas reutilizações, assim lidando com tolerância de falhas \cite{MapReduce08}.

\subsection{Modelo de programação}\label{ssec:mapreducemodelo}

A computação recebe um arquivo de entrada e produz um conjunto de objetos (CHAVE, VALOR). O usuário cria as funções \textit{Map} e \textit{Reduce} de acordo com sua aplicação e objetivo. Cada função \textit{Map} recebe uma parte do arquivo de entrada e produz um conjunto intermediário de objetos do tipo (CHAVE, VALOR). Em seguida, a fase intermediária \textit{Shuffle} agrupa os valores com a mesma chave, os quais servirão de entrada para a função \textit{Reduce}. Nesse momento a função \textit{Reduce} unifica os valores com a mesma chave de modo a criar um conjunto menor, fazendo com que seja possível lidar com listas muito grandes para a memória disponível \cite{MapReduce08}. 

Entre o momento que são executadas as funções \textit{Map} e \textit{Reduce}, existe a fase \textit{Shuffle}, que é criada automaticamente em tempo de execução e executa operações de ordenação (\textit{sort}) e junção (\textit{merge}) \cite{ProHadoop09}. Para \textcite{HadoopBook15}, a operação \textit{Shuffle} é um dos fatores mais influentes no bom desempenho de aplicações \textit{MapReduce}, uma vez que operações de ordenação e junções podem prejudicar ou melhorar muito um algoritmo conforme sua implementação.

Como exemplo, considere-se o problema de contar quantas vezes determinada palavra aparece em um documento. Nesse problema, as funções \textit{Map} e \textit{Reduce} seriam similares ao \autoref{code:codigo1} e ao \autoref{code:codigo2} \cite{MapReduce08}:

\begin{lstlisting}[caption={Exemplo de função Map em pseudocódigo adaptado de \cite{MapReduce08}}, label=code:codigo1]
map(String chave, String valor):
// chave: nome do documento
// valor: conteudo do documento

  para cada palavra W em valor:
    criaIntermediario(W, 1);
\end{lstlisting}

% \newpage
\begin{lstlisting}[caption={Exemplo de função Reduce em pseudocódigo adaptado de \cite{MapReduce08}}, label=code:codigo2]
reduce(String chave, Iterador valores):
// chave: uma palavra
// valores: lista de contagens

  int resultado = 0;
  para cada V em valores:
    resultado = resultado + 1;
  cria(resultado);
\end{lstlisting}

\newpage
A função \textit{Map} gera um objeto intermediário de cada palavra associada a uma lista do seu número de ocorrências no texto e a função \textit{Reduce} soma os valores até que essas ocorrências por palavras sejam totalizadas. Os parâmetros de entrada e saída são configurados pelo usuário, assim como os parâmetros de configuração que poderão ser usados no \textit{\gls{tuning}} para melhorar o desempenho da aplicação.

Para exemplificar, considere um arquivo de texto com três linhas nas quais estão as seguintes frases, respectivamente, uma em cada linha: "vamos para casa", "na minha casa", "para na casa". Nesse exemplo, a função \textit{Map} é chamada três vezes, uma para cada linha, gerando os pares (CHAVE, VALOR) intermediários, um para cada palavra encontrada no texto, como é mostrado na \autoref{fig:fig1}. Para cada palavra distinta ("vamos", "para", "casa", "na", "minha"), é executada a função \textit{Reduce}, que soma quantas vezes cada uma dessas palavras apareceu no texto e gera um arquivo de saída.

\figura{Execução Genérica do MapReduce}{1.00}{fig/fig1.png}{A autora (2022)}{fig1}{}{}

\subsection{Execução do MapReduce}\label{ssec:execucaomapreduce}

O \textit{MapReduce} funciona usando uma estrutura Cliente/Servidor sobre um \textit{cluster} que, segundo \textcite{MapReduce08}, consiste em primeiramente particionar os dados de entrada em blocos de tamanho já definidos e depois distribuir cópias do programa \textit{MapReduce} entre cada um desses blocos. Existe uma cópia \textit{Master}, que é responsável por repartir as tarefas (\textit{tasks}), enquanto as demais cópias - denominadas Workers - recebem da \textit{Master} as tarefas junto com os arquivos de entrada. Ao finalizar a execução de uma tarefa do tipo \textit{Map}, a cópia Worker responsável repassa a \textit{Master} os arquivos de saída e esta repassa a um Worker esse arquivo com a tarefa de \textit{Reduce}. Por fim, esse \textit{Worker} executa a redução, lendo os pares intermediários que passaram pela fase \textit{Shuffle} e agrupando as instâncias de mesma chave. Quando todas as tarefas \textit{Map} e \textit{Reduce} forem executadas, o programa é finalizado.

Na \autoref{fig:fig1} foi possível ver como o \textit{MapReduce} funcionaria em pequena escala. Uma das maiores vantagens do \textit{MapReduce} é, no entanto, sua escalabilidade, visto que ele permite uma execução distribuída entre uma grande quantidade de nodos. A \autoref{fig:fig2}  representa uma execução genérica do \textit{MapReduce}, descrita no parágrafo acima.

\figura{Exemplo de execução do MapReduce}{.900}{fig/fig2.png}{Adaptado de \cite{MapReduce08}}{fig2}{}{}

\section{HADOOP} \label{sec:hadoop}

\textit{Hadoop} é um \textit{\gls{framework}} desenvolvido na linguagem Java pela Apache Software Foundation com os seguintes princípios arquiteturais, segundo \textcite{ImprovingNavarro18}:
\begin{itemize}
  \item A possibilidade de escalar o sistema ao adicionar nodos no \textit{cluster}.
  \item Possibilidade de funcionar bem em \textit{\gls{hardware}} que não necessite ser caro e de luxo.
  \item Tolerância a falhas, com implementações que as identificam e permitem que o sistema funcione independentemente da existência delas.
  \item Fornecimento de serviços para que o usuário foque no problema que deseja resolver.
\end{itemize}

Esse \textit{\gls{framework}} disponibiliza ferramentas para que o usuário possa escrever as funções necessárias em diversas linguagens de programação, conforme a necessidade do programador. O \textit{\gls{framework}} funciona na mesma estrutura de Cliente/Servidor apresentada anteriormente, utilizada pelo \textit{MapReduce}. Além disso, oferece ao programador um sistema paralelo e distribuído (\textit{Hadoop HDFS}), com os recursos ocultos ao usuário, mas capaz de lidar com a comunicação entre as máquinas e quaisquer falhas que possam vir a ocorrer e o escalonamento das tarefas.

Além do \textit{Hadoop Map Reduce} e do \textit{Hadoop HDFS}, existem outros subprojetos do \textit{Hadoop} que compõem sua estrutura principal: o \textit{Hadoop Common}, que fornece ferramentas comuns aos outros subprojetos e o \textit{Hadoop YARN}, um \textit{\gls{framework}} para escalonamento de tarefas e gerenciamento de recursos em \textit{clusters}.

\subsection{Hadoop Common}\label{ssec:hadoopcommon}

Esse subprojeto contém os utilitários e bibliotecas comuns aos outros subprojetos. Por exemplo, funções de manipulação de arquivos, funções auxiliares de serialização de dados, etc \cite{GoldmanApache12}.

\subsection{Hadoop HDFS}\label{ssec:hadoophdfs}

O \textit{Hadoop HDFS} é um sistema de arquivos distribuídos criado para funcionar em \textit{\gls{hardware}} facilmente obtido e relativamento barato. Suas características principais são a alta capacidade de lidar com falhas e a possibilidade de ser usado com aplicações que possuem grande quantidades de dados como entrada \cite{HDFSDesign20}.

Uma instância HDFS é composta de centenas ou milhares de máquinas, cada uma responsável por armazenar uma parte dos dados do sistema. Dessa forma, a rápida detecção e recuperação de falhas é essencial para sua estrutura. Seu \textit{design} foi pensado em aplicações de processamento de dados em blocos e o tamanho de seus arquivos pode variar entre Gigabytes e Terabytes. Além disso, é adaptado para funcionar em diferentes plataformas e prover interfaces que possibilitam mover a aplicação para perto dos dados, permitindo que qualquer operação computacional aplicada seja muito mais eficiente \cite{HDFSDesign20}.

O \textit{Hadoop HDFS} também possui uma estrutura Cliente/Servidor, em que o \textit{Namenode} - responsável por gerenciar o sistema e regular os acessos aos arquivos - é o nodo \textit{Master} e os \textit{Datanodes} - responsáveis por gerenciar o armazenamento dos nodos aos quais eles estão conectados - são os nodos Worker. O sistema é implementado usando uma estrutura comum de diretórios na qual é possível criar, mover, renomear e remover arquivos, mas ainda não implementa funções como quota de usuários, permissões de acesso ou \textit{links} simbólicos \cite{HDFSDesign20}.

Uma das características essenciais desse sistema é sua capacidade de lidar com grandes quantidades de dados. Isso é realizado através do armazenamento dos arquivos como uma sequência de blocos, cujo tamanho e fator de replicação são configuráveis pelo usuário, mas possuem um valor padrão de 64MB. Periodicamente, o \textit{Namenode} recebe dos \textit{Datanodes} um sinal indicando se o funcionamento está correto. O posicionamento e a quantidade de réplicas de um bloco é crítica na análise da boa performance do HDFS, e é um dos fatores que o diferencia de outros sistemas de arquivos distribuídos. A escolha correta dos valores de posicionamento e replicação pode aumentar a confiabilidade, a disponibilidade e o uso de redes do sistema \cite{HDFSDesign20}.


\subsection{Hadoop MapReduce} \label{ssec:hadoopmapreduce}

O \textit{Hadoop MapReduce} é um \textit{\gls{framework}} que implementa o modelo de programação \textit{MapReduce} para facilitar a criação de aplicações que são capazes de processar grandes quantidades de dados em paralelo em \textit{clusters} de uma forma confiável e com tolerância a falhas. 

Esse \textit{\gls{framework}} é constituído de um \textit{Job} responsável por dividir os arquivos de entrada em blocos independentes que serão processados pelas tarefas (\textit{tasks}) \textit{Map}, ordenados na fase \textit{Shuffle} e inseridos nas tarefas \textit{Reduce} de forma paralela. Os arquivos de entrada e saída são armazenados no sistema de arquivos e o sistema é responsável pelo escalonamento, agendamento e reexecução de tarefas que tenham falhado \cite{HadoopMapReduce22}.

A estrutura Cliente/Servidor tem como nodo \textit{Master} o \textit{JobTracker}, e como nodos Worker os \textit{TaskTrackers}. Como apresentado anteriormente, o nodo \textit{Master} designa as tarefas e os nodos Worker as executam. A aplicação do programador fornece o local dos arquivos de entrada e saída, a implementação das funções de \textit{Map} e \textit{Reduce} e outros parâmetros de configuração do \textit{Job}. Então, o cliente \textit{Hadoop} envia o \textit{Job} e o arquivo de configuração para o \textit{JobTracker}, que distribui as tarefas e controla o funcionamento desse \textit{Job}.

\subsection{Hadoop YARN} \label{ssec:hadoopyarn}

O \textit{Hadoop YARN} é um subprojeto que tem como objetivo dividir as funcionalidades de gerenciamento de recursos de escalonamento de tarefas em módulos diferentes, sendo composto então de um gerenciador global de recursos e um gerenciador local por aplicação \cite{GoldmanApache12}. 

O gerenciador global trabalha em conjunto com um gerenciador de nodos responsável pelos contêineres e pelo monitoramento de uso de recursos, como CPU, memória, uso de disco e uso de redes, assim como o repasse dessas informações para o gerenciador global \cite{HadoopYarn22}.

O YARN foi adicionado ao \textit{Hadoop} na versão 2.0, permitindo a separação das camadas de gerenciamento de recursos que possam ser alocados pela aplicação. Com essa camada independente, ilustrada na \autoref{fig:fig3}, as aplicações \textit{MapReduce} podem ser utilizadas em conjunto com aplicações não \textit{MapReduce}. Além disso, esse formato de implementação possibilita economizar custos com o melhor aproveitamento dos nodos \cite{KobylinskaMartins14}. 

\figura{Nova arquitetura do Hadoop 2.0}{.700}{fig/fig3.png}{\cite{KobylinskaMartins14}}{fig3}{}{}

\newpage
\section{VIRTUALIZAÇÃO} \label{sec:virtualizacao}

Virtualização é o processo de criar um ambiente ou uma versão virtual de algum componente computacional, tal como \textit{\gls{hardware}s}, dispositivos de armazenamento e recursos de rede. A virtualização permite que haja economia nos custos de \textit{\gls{hardware}}, melhoria na recuperação em caso de falhas e redução da necessidade de espaço físico para \textit{\gls{datacenters}} \cite{PortnoyVirtualization12}. 

Uma das técnicas da virtualização é a utilização de contêineres. Contêineres, uma virtualização a nível de sistema, permitem que existam múltiplos espaços do usuário por cima de um determinada \textit{\gls{kernel}} de sistema. 

\figura{Arquitetura Docker}{0.850}{fig/fig4.png}{\cite{DockerDocs22}}{fig4}{}{}
\newpage
\textit{Docker} é uma ferramenta que tem como objetivo automatizar a implantação de aplicações em contêineres, cuja estrutura geral está ilustrada na \autoref{fig:fig4}. Essa ferramenta acrescenta uma implantação de uma aplicação sobre um ambiente de execução em um contêiner, ou seja, simula um ambiente virtual de modo que o programador possa trabalhar com sua aplicação em produção de forma extremamente configurável para as suas necessidades. Para isso, o \textit{Docker} utiliza um recurso de imagem que se refere aos arquivos de sistemas que determinada aplicação necessita para ser executada. Dessa forma, esses arquivos são empilhados entre si e servem como uma receita para construção de um ou de múltiplos contêineres \cite{DockerBook14}.

